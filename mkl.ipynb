{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "456651f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbowe\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 28s 3s/step - loss: 56.3086 - accuracy: 0.0233 - val_loss: 3.7933 - val_accuracy: 0.0612\n",
      "Epoch 2/15\n",
      "11/11 [==============================] - 27s 3s/step - loss: 3.7982 - accuracy: 0.0465 - val_loss: 3.8038 - val_accuracy: 0.0408\n",
      "Epoch 3/15\n",
      "11/11 [==============================] - 27s 3s/step - loss: 3.7883 - accuracy: 0.0233 - val_loss: 3.7515 - val_accuracy: 0.1633\n",
      "Epoch 4/15\n",
      "11/11 [==============================] - 28s 3s/step - loss: 3.5827 - accuracy: 0.0698 - val_loss: 2.8973 - val_accuracy: 0.4490\n",
      "Epoch 5/15\n",
      "11/11 [==============================] - 27s 3s/step - loss: 2.8917 - accuracy: 0.2093 - val_loss: 2.0507 - val_accuracy: 0.5714\n",
      "Epoch 6/15\n",
      "11/11 [==============================] - 27s 3s/step - loss: 2.4089 - accuracy: 0.3953 - val_loss: 1.6291 - val_accuracy: 0.5918\n",
      "Epoch 7/15\n",
      "11/11 [==============================] - 27s 3s/step - loss: 1.8234 - accuracy: 0.4302 - val_loss: 1.2067 - val_accuracy: 0.6327\n",
      "Epoch 8/15\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.5834 - accuracy: 0.5465 - val_loss: 0.9677 - val_accuracy: 0.6327\n",
      "Epoch 9/15\n",
      "11/11 [==============================] - 27s 3s/step - loss: 1.7295 - accuracy: 0.5814 - val_loss: 0.9507 - val_accuracy: 0.6735\n",
      "Epoch 10/15\n",
      "11/11 [==============================] - 28s 3s/step - loss: 1.8154 - accuracy: 0.5116 - val_loss: 0.8873 - val_accuracy: 0.7347\n",
      "Epoch 11/15\n",
      "11/11 [==============================] - 28s 3s/step - loss: 1.7528 - accuracy: 0.5465 - val_loss: 0.5680 - val_accuracy: 0.7959\n",
      "Epoch 12/15\n",
      "11/11 [==============================] - 28s 3s/step - loss: 1.3215 - accuracy: 0.6163 - val_loss: 0.4865 - val_accuracy: 0.8776\n",
      "Epoch 13/15\n",
      "11/11 [==============================] - 28s 3s/step - loss: 1.2744 - accuracy: 0.6512 - val_loss: 0.4331 - val_accuracy: 0.8980\n",
      "Epoch 14/15\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.9639 - accuracy: 0.7209 - val_loss: 0.5067 - val_accuracy: 0.7959\n",
      "Epoch 15/15\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.9008 - accuracy: 0.7326 - val_loss: 0.9693 - val_accuracy: 0.7755\n",
      "Test loss: 0.9692628979682922\n",
      "Test accuracy: 0.7755101919174194\n",
      "2/2 [==============================] - 3s 916ms/step\n",
      "Confusion Matrix:\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "characters = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!@#$%^&()')\n",
    "# Parameters\n",
    "image_size = (200, 200)\n",
    "input_shape = (*image_size, 4)  # 4 for RGBA\n",
    "n_classes = len(characters)\n",
    "batch_size = 8 \n",
    "epochs = 15\n",
    "\n",
    "# Load the image data\n",
    "image_files = []\n",
    "labels = []\n",
    "for char in characters:\n",
    "    for num in range(2, 5):\n",
    "        filename = f'distorted_outlined_{char}_{num}.png'\n",
    "        if os.path.exists(filename):\n",
    "            img = load_img(filename, target_size=image_size, color_mode='rgba')\n",
    "            img_array = img_to_array(img)\n",
    "            image_files.append(img_array)\n",
    "            labels.append(char)\n",
    "        else:\n",
    "            print(f\"File not found: {filename}\")\n",
    "encoder = OneHotEncoder(categories=[characters], handle_unknown='ignore')\n",
    "\n",
    "labels = np.array(labels).reshape(-1, 1)\n",
    "labels = encoder.fit_transform(labels).toarray()\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_files, labels, test_size=0.36, random_state=42, stratify=labels)\n",
    "\n",
    "\n",
    "\n",
    "# Build the model with increased complexity and regularization\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(n_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.fit(datagen.flow(np.array(X_train), np.array(y_train), batch_size=batch_size),\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(np.array(X_test), np.array(y_test)),\n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(np.array(X_test), np.array(y_test), verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "model.save('trained_model.h5')\n",
    "\n",
    "y_pred = model.predict(np.array(X_test))\n",
    "predicted_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convert one-hot encoded labels back to original labels\n",
    "true_classes = np.argmax(np.array(y_test), axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confusion_mat = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Convert predicted_classes and true_classes back to one-hot-encoded form\n",
    "predicted_classes_onehot = keras.utils.to_categorical(predicted_classes, num_classes=n_classes)\n",
    "true_classes_onehot = keras.utils.to_categorical(true_classes, num_classes=n_classes)\n",
    "\n",
    "# Inverse transform the labels\n",
    "predicted_classes_labels = encoder.inverse_transform(predicted_classes_onehot)\n",
    "true_classes_labels = encoder.inverse_transform(true_classes_onehot)\n",
    "\n",
    "# Map from index to original labels\n",
    "index_to_label_map = {i: char for i, char in enumerate(characters)}\n",
    "\n",
    "predicted_classes_labels = [index_to_label_map[i] for i in predicted_classes]\n",
    "true_classes_labels = [index_to_label_map[i] for i in true_classes]\n",
    "\n",
    "# Compute the confusion matrix with original labels\n",
    "confusion_mat_labels = confusion_matrix(true_classes_labels, predicted_classes_labels)\n",
    "\n",
    "# Print the confusion matrix\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'confusion_mat' is the confusion matrix\n",
    "np.set_printoptions(threshold=np.inf)  # Set the threshold to infinity to print the entire matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "afc48c57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
      "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
      "       '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '!', '@', '#',\n",
      "       '$', '%', '^', '&', '(', ')'], dtype='<U1')]\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "{0: 1, 1: 1, 2: 6, 3: 1, 5: 2, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 17: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 2, 31: 1, 32: 1, 33: 1, 34: 1, 35: 1, 36: 1, 37: 2, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 1}\n",
      "{0: 2, 1: 2, 2: 2, 3: 2, 4: 2, 5: 2, 6: 1, 7: 2, 8: 2, 9: 2, 10: 2, 11: 2, 12: 2, 13: 2, 14: 2, 15: 2, 16: 1, 17: 2, 18: 2, 19: 2, 20: 2, 21: 2, 22: 2, 23: 2, 24: 2, 25: 2, 26: 2, 27: 2, 28: 2, 29: 2, 30: 1, 31: 2, 32: 2, 33: 2, 34: 2, 35: 2, 36: 2, 37: 1, 38: 2, 39: 2, 40: 2, 41: 2, 42: 2, 43: 2, 44: 2}\n",
      "{0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 2, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 2, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 2, 31: 1, 32: 1, 33: 1, 34: 1, 35: 1, 36: 1, 37: 2, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 1}\n",
      "{0: 1, 1: 1, 2: 6, 3: 1, 5: 2, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 17: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 2, 31: 1, 32: 1, 33: 1, 34: 1, 35: 1, 36: 1, 37: 2, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 1}\n",
      "Index 0 corresponds to label 'A'\n",
      "Index 1 corresponds to label 'B'\n",
      "Index 2 corresponds to label 'C'\n",
      "Index 3 corresponds to label 'D'\n",
      "Index 4 corresponds to label 'E'\n",
      "Index 5 corresponds to label 'F'\n",
      "Index 6 corresponds to label 'G'\n",
      "Index 7 corresponds to label 'H'\n",
      "Index 8 corresponds to label 'I'\n",
      "Index 9 corresponds to label 'J'\n",
      "Index 10 corresponds to label 'K'\n",
      "Index 11 corresponds to label 'L'\n",
      "Index 12 corresponds to label 'M'\n",
      "Index 13 corresponds to label 'N'\n",
      "Index 14 corresponds to label 'O'\n",
      "Index 15 corresponds to label 'P'\n",
      "Index 16 corresponds to label 'Q'\n",
      "Index 17 corresponds to label 'R'\n",
      "Index 18 corresponds to label 'S'\n",
      "Index 19 corresponds to label 'T'\n",
      "Index 20 corresponds to label 'U'\n",
      "Index 21 corresponds to label 'V'\n",
      "Index 22 corresponds to label 'W'\n",
      "Index 23 corresponds to label 'X'\n",
      "Index 24 corresponds to label 'Y'\n",
      "Index 25 corresponds to label 'Z'\n",
      "Index 26 corresponds to label '0'\n",
      "Index 27 corresponds to label '1'\n",
      "Index 28 corresponds to label '2'\n",
      "Index 29 corresponds to label '3'\n",
      "Index 30 corresponds to label '4'\n",
      "Index 31 corresponds to label '5'\n",
      "Index 32 corresponds to label '6'\n",
      "Index 33 corresponds to label '7'\n",
      "Index 34 corresponds to label '8'\n",
      "Index 35 corresponds to label '9'\n",
      "Index 36 corresponds to label '!'\n",
      "Index 37 corresponds to label '@'\n",
      "Index 38 corresponds to label '#'\n",
      "Index 39 corresponds to label '$'\n",
      "Index 40 corresponds to label '%'\n",
      "Index 41 corresponds to label '^'\n",
      "Index 42 corresponds to label '&'\n",
      "Index 43 corresponds to label '('\n",
      "Index 44 corresponds to label ')'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(encoder.categories_)\n",
    "#print(len(labels[:10]))\n",
    "print(labels[:10])\n",
    "print(np.unique(y_train, axis=0))\n",
    "print(np.unique(y_test, axis=0))\n",
    "\n",
    "\n",
    "#print(np.unique(predicted_classes, return_counts=True))\n",
    "\n",
    "unique, counts = np.unique(predicted_classes, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "unique, counts = np.unique(np.argmax(y_train, axis=1), return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(np.argmax(y_test, axis=1), return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "unique, counts = np.unique(predicted_classes, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "for index, label in enumerate(encoder.categories_[0]):\n",
    "    print(f\"Index {index} corresponds to label '{label}'\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2b020f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels before any transformation: 135\n",
      "Number of unique classes in y_train before one-hot encoding: 108\n",
      "Number of unique classes in y_test before one-hot encoding: 27\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique labels before any transformation: {len(labels)}\")\n",
    "\n",
    "\n",
    "print(f\"Number of unique classes in y_train before one-hot encoding: {len(y_train)}\")\n",
    "print(f\"Number of unique classes in y_test before one-hot encoding: {len(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "192dd193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 10s 10s/step\n",
      "Predicted Label: I\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAEcCAYAAADDS24xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWM0lEQVR4nO3dfbRkVX3m8e9DN2230oBAotBAo4jGGGfQFaJMJPaKEh0jidExZDSzjE4YzYwaXe1gTESIYpSMSRSjS2NGQTG+RCcsQYmKEyGoo/gSVBQJLyIIxG66m1dtGvjNH+dcu/pyX6pf6tatfb+ftWr1vXVO7fOrrj67n9p716lUFZIkSS3ba9wFSJIkjZqBR5IkNc/AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8Y5TkXUlOGXcdw0hyWpJzxl2HJC20JJ9P8vvjrkO7x8AzIkm+n+THSW5PsiXJF5O8JMlP/86r6iVV9YYh23rqHqhnt9qYo+11SW4YRduSds1AH3RHkpuTnJVkn3HXNZMkleQRI2r7iL795SNq3zeDE8LAM1onVNVqYC3wZuDVwP9eyAJGdZJLmggnVNU+wNHA44DXjLecXWM/pj3BwLMAqurWqvoEcCLwgiS/ANC/4zq9//mgJOf3o0Gbkvxzkr2SfAA4HDivf6d2cr//byS5vN//80kePXW8/p3dq5N8E7gzyYdmaeOJ/cjTliSXJVk30MbDklzUj1B9Fjho2Ofb13N63/YdSc5LcmCSDya5LcmlSY4Y2P9tSa7vt30tyXED21YlOTvJ5iTfTXLy4GhSkkOSfDzJhiTXJnn5Trw00pJQVTcDn6YLPsC85/8BSd6X5Mb+3Dt3YNtJSa7q+6lPJDlkYFv1I9n/2j/uHUnSb3tE36fcmmRjko/091/cP/yyvr84cWrUuO/Hbgbel+T3klwy+LwGR4b6vuIvklzXH+OSJKuAqfa39O0f2+//or5P2Zzk00nWDrR7fJIr+nb+Gsiwf9d9Tf+9/zu4PckbkhyZ5Et9H/fRJCv6fR+crt/f0NdxfpJDB9p6WJKL+3Yu7P8+zxnYPutrqBlUlbcR3IDvA0+d4f4fAH/Q/3wWcHr/85uAdwF797fjgMzUFvBI4E7g+H7fk4GrgBUD+/8LcBiwapY21gC3AM+gC77H97//TL/9S8BfAg8AfgW4HThnlue6Drhh4PfP9/UcCewHfAe4EngqsBx4P/C+gf1/Fziw37YeuBlY2W97M3AR8GDgUOCbU8fq6/4a8DpgBfBw4BrgaeN+/b15G/dt8Jzvz51vAW/rf5/v/P8k8JH+vNsbeHJ//68CG4HH933D24GLB45ZwPnA/nRvsjYAT++3fQj4k/54K4EnTXvcIwZ+XwfcA5zRH2cV8HvAJdOe408fB7yj73vWAMuA/9A/9oh+v+UDj3tW30c9uu93Xgt8sd92EHAb8J/65/7Kvpbfn+Xv+TQG+sb+WJ8A9gUeA2wFPtf3T1P94Qv6fQ8EngM8EFgN/D1w7kBbXwLe0vdvT+rrOmeY19Db/W+O8Cy8G4EDZrh/G3AwsLaqtlXVP1f/r3oGJwKfrKrPVtU2uhNiFd0JPuXMqrq+qn48Sxu/C3yqqj5VVfdV1WeBrwLPSHI4cAxwSlVtraqLgfN28nm+r6qurqpbgQuAq6vqwqq6h+6kftzUjlV1TlXdUlX3VNVf0HVSj+o3/zbwZ1W1uapuAM4cOMYxdCf366vq7qq6BngP8Ds7WavUqnOT3A5cD/wIOLW/f67z/2DgPwIv6c+7bVV1Uf+45wPvraqvV9VWuimyYwdHbIE3V9WWqvoB8E9sH1XaRje9f0hV/aSqdhitmcF9wKl9HzRbPwZAurWRLwL+sKp+WFX3VtUX+xpn8mLgTVX13b5P+jPg6H6U5xnAd6rqY33/+la6N2E744yquq2qLge+DXymqq4Z6A8fB9D3ex+vqruq6nbgjcCT++c01Q+/ru/fLqELUlNmfQ13stYlw8Cz8NYAm2a4/3/RveP4TJJrkvzRHG0cAlw39UtV3UfXoa0Z2Of6eepYCzy3HwrdkmQL3TuIg/v2N1fVnQP7XzdDG3P5t4GffzzD7z9dPJlkfT+0fGtfx35sn0I7ZNpzGfx5LXDItOfwx8BDdrJWqVXPqm4d4Trg59h+Xs11/h8GbKqqzTO0N73vuYNuVGGw7xkMB3ex/Vw/mW5q6CvppuNfNE/tG6rqJ/M/RaB7XiuBq4fcfy3wtoHnvqmvbQ3T+pz+jed8/el0Q/V/SR6Y5N39NNxtdNNv+ydZ1texqaruGnjs9P5vttdQM3Ah2AJKcgzdCXW/dzZ9ul8PrE/yGOCfklxaVZ+jGyIddCPw2IF2Q9dJ/XCwyemHmPb79cAHquqkGepcCzw4yYMGQs/hM7Sx29Kt13k18BTg8qq6L8lmts+Z30Q3HP+d/vfDpj2Ha6vqqD1dl9SSqrooyVl0o8HPYu7z/2DggCT7V9WWaZtvpPuPdmrfB9FNy/yQeVS3juik/nFPAi5McnFVXTXbQ6b9fifd1M/UsR86sG0j8BO6afTL5mkHuuf/xqr64PQNSY5ioJ8Z6F9HYT3daPYTqurmJEcD36Dr/26iex0eOBB6pvd/M76GmpkjPAsgyb5Jngl8mG7+9Vsz7PPMdIv6QjdPe29/g+7dwcMHdv8o8OtJnpJkb7qTZivwxTnKmN7GOcAJSZ6WZFmSlekWCh5aVdfRDY3+aZIVfed0wi49+fmtppsf3wAsT/I6urnvKR8FXtMv7lsDvHRg21eA29ItbFzVP49f6IOlpB29FTi+/091rvP/Jrppl3f2593eSX6lb+PvgBcmOTrJA+imgr5cVd+f7+BJnjuwIHczXRCZrY+byWXAY/pjr6RbOwP8dJT7vcBfpvsgw7Ikx/Y1bqCbHhts/110/cpj+tr2S/Lcftsn++M8O92nw14ODIarPWk13YjPliQHsH3KkYF++LS+Hz6WHfvhWV/DEdU68Qw8o3XewPz5n9AtAn7hLPseBVwI3EG3UO2dVfX5ftubgNf2w5avqqrv0c3fvp3unc0JdB8/vXuOWqa3cT3wm3RTQBv6Gv8n2/9NPA94At1Q76l0C41H4dN0neuVdEPlP2HHYdvXAzcA19L9/XyMLtxRVffSPfej++0bgb+lmxKTNKCqNtCdx6cMcf7/F7o1N1fQrf15Rd/G54BTgI/TjUAcyfBr5o4BvpzkDrq1KH9YVdf2204Dzu77p9+epf4r6fqDC4F/5f4j5a+iW5h9KV2/dQawVz868kbgC337T6yqf+i3f7ifSvo23bolqmoj8Fy6D0zcQtc3f2HI57iz3kq3/nIj8P+Af5y2/fnAsX0dp9MtJJ/q/+Z7DTXN1KeApImQ5A+A36mqJ4+7FklaSOk+yn9FVZ067866H5OgFrUkByf55XTXJHoU3fTdP4y7LkkatSTHpLuGz15Jnk43onPumMuaWC5a1mK3Ang38DBgC906qHeOsyBJWiAPBf4P3cLwG+iu4faN8ZY0uZzSkiRJzXNKS5IkNc/AI0mSmucaHknNSuKcvbTEVNWMX/bqCI8kSWqegUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1DwDjyRJap6BR5IkNc/AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8kiSpeQYeSZLUPAOPJElqnoFHkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1DwDjyRJap6BR5IkNc/AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8kiSpeQYeSZLUPAOPJElqnoFHkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1DwDjyRJap6BR5IkNc/AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8kiSpeQYeSZLUPAOPJElqnoFHkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1DwDjyRJap6BR5IkNW/5uAtQ+5Icyf3D9TVVde846pEkLT2pqnHXoIYlWQ5sAlYP3F3Amqq6aTxVaalIYgcnLTFVlZnud4RnCUpyBXDQDJtOAb4BfBw4oqq2JXkpcNruHA7YZzceL0nSbjPwNCzJMuD9wIrBu4G1wLuAe4BXDWx7MbAZeAjwkST3Ao8EDhzY5wxgFfDyeQ7/98CXgbfsxlOQJGmPMPA0KMm/A34eWAY8B3hAv+kO4Lz+52UzPPTfD/z8W7M0v7x/7I+Bc4HfAB40w37LgL13pm5JkkbFNTyNSBK2T1O9BnjlDLt9H/gl4DvMPKU1lwI2AvvSBah/Ax4LfA04bBfacg2PRs41PNLSM9saHgNPI5LsS7c4eOrTUDO94IMv9oz/IOZwH93U1lnAb+5mWwYeLQgDj7T0zBZ4vA5PA5KsAy6jez3D7AEk07ZfADyeHcPL0Iftb8cBH9yFx0uStGAMPBMuyfOA9cARbA8y5wF/PsTD7wSuG/ZQfZuPBb4C/DFdUDqJHdf+SJK06LhoefL9KvDMafdtoFuvM+XrdAuLH0UXUi4BjtqFYz2K7no6VwNX9ve9YBfakSRpQbmGZ4IlWUn38fL5QsfTgUcDf0UXeB4CvI3uU1QvBn7A/Otw7gMOBf6G+wes6VYy9+iha3i0IFzDIy09XniwTd8FDh9iv/OZJdBU1aYk+w9zsKq6p59Cmy8cfQV43DBtSpK0EAw8k21vhluHNfU630B3fZ3NwGvpg0tV3TPsAYf5/ivfVUuSFhsDzwRKshp4GTt+P9VczqFbnLypqr7a33fNKGqTJGkxMvBMpn2B05l7auku4Kr+5zOr6tJRF5VkL7orPK+aY7e7gSuAbaOuR5KkKQaedl0OPLGq7lvAY66i+/LR5XSLnOH+U243V5UfY5ckLSivw9OuxwMbksw12jJKf053UUJJksbOEZ52XQ28Atg6puM/B/jlMR1b0tJxG/A85r9ifIAPA/uMvCItSgaeCZPkKLpvKJ/PrVV1wajrmcNR7NrFDSVpZ2yrqk/Ot1P/BcuuHVzCDDyT5zjgLeMuQpKkSeIaHkmS1DwDz+T5MPCLzD1ffQbw6wtTjiRJi5+BZ8JU1V3AzfPs9lS678haaFvpvj39vwLnzrLPAUn+Nsl+C1aVJGnJM/BMmCSHAk+ZZ7d9gAMXoJwdVNU9VXVWVb2X7hvaZ7IP8CLghCRrFq46SdJSZuCZPL8GnM3cV1l+f1W9coHq2RUBPkA3EiVJ0sgZeCRJUvMMPBMkyTuAPx13HXvQG5KcOe4iJEntM/BMlocBhw6x3/FJXjLqYvaAw4C14y5CktQ+Lzw4Wa4Efo4u+MxlHfCzSb7a//69qrp9lIVJkrSYOcIzQarqFcDrGe7y6D8PXNrfnpBkeZJlIyxPkqRFy8AzeT5AF2bm+6K8QecBtwKXjaQiSZIWOae0JkxV3ZvkerqPdH8EOGiIh63s/3x4kgtHVtyO5pt2kyRpwRh4JlBVbQX+b5J3A79FN+IzjFXMf9FCSZKaY+CZYFX12iTLgQOAh467HkmSFivX8Ey4qvojuu+uqoGbJEkaYOBpw4XAQ/rbFWOuRZKkRccprQZU1d3ABoAk64H9gCOB08dZlyRJi4UjPI2pqguAbzHctXokSVoSHOFpRJIA+9N9E/kLgfVjLUiSpEXEwNOO1cCPAK+mLEnSNAaeBiR5MvAeurCTIR+2Hjh/ZEXB/wBePsL2JUkamoFnwiU5ETgROGqI3W8B3tj//KmqunKEdW0cVduSJO0sA8/kO57uastz+Sbdd2ndWFV/NfqSJElaXAw8EyzJCuZes1PAVuBlVXXxwlQlSdLiY+CZbFcAh8+x/R66r5y4bWHKkSRpcfI6PBMoyc8k+QJwCPN/KuvuqvLrJiRJS5ojPJNpBXAsc38i6ybgbLpRHkmSljQDT7tuqKrXjLsISZIWA6e0JElS8ww8kiSpeQYeSZLUPNfwTJgkRwLPGHcdkiRNEkd4Js8vAacw/HdmSZK05Bl4JkxVfQh4PN1VlCVJ0hAMPJPJsCNJ0k4w8LRrbZK/TrL3uAuRJGncDDzt+lngv+HCdEmSDDxLwIOS+DpLkpY0/yNs23K679Q6btyFSJI0TgaeyfQj4Bf7P+cSutDzN0lOHnlVkiQtUgaeCVRV26rq68C2IR/ySODZSV42wrIkSVq0XNA62S4HVgIHDrHvE4A1SS6eZ787q+qq3a5sONcB1y7QsSRJS5iBZ4JV1dOSvAd4IbBsiIccCvzLPPtckmTd7lUGDDd6eGpVnb0HjiVJ0pwMPJPvpcA/Ah/bQ+0dC2zeA+2s2ANtSJK0Rxh4JlxVbU1yEfBsutCzu+uylgGrd7uwuRXwfOCiER9HkiTARctNqKqNwAXAe4BNYy5nPnfQ1fmpqrpx3MVIkpaGVPm1TC1J8hm6Bcr7jruWGdwBfLuqjh13IVoaktjBte+Wqjpovp2SBLgFePDoS9I4VVVmut8RnsZU1a8Bb6ebNlpMnX0Bf2fYkSSNgyM8DUqyGtiHbo3W94BV460IgP8MXFBVt467EC0djvAsCY7waAezjfC4aLlBVXU7cHt/gp/E/V/nM1mYKa/rgFP7ny827EiSxsXA07Dqhu8+OP3+JE8B9luAEq71OjuSpMXAKS1JzXJKa0lwSks7cNGyJElasgw8kiSpeQYeSZLUPAOPJElqnoFHkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvOWj7sASZJ2w/Ik64CaZ7/g/3lLWqrm+zciSZMpiR2ctMRUVWa63yktSZLUPAOPJElqnoFHkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1DwDjyRJap6BR5IkNc/AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8kiSpeQYeSZLUPAOPJElqnoFHkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1DwDjyRJap6BR5IkNc/AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8kiSpeQYeSZLUPAOPJElqnoFHkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1DwDjyRJap6BR5IkNc/AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8kiSpeQYeSZLUPAOPJElqnoFHkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5qapx1yBJkjRSjvBIkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXv/wNfbxLHbYAXBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Parameters\n",
    "characters = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!@#$%^&()')\n",
    "image_size = (200, 200)\n",
    "input_shape = (*image_size, 4)  # 4 for RGBA\n",
    "n_classes = len(characters)\n",
    "\n",
    "# Load the trained model\n",
    "model = keras.models.load_model('trained_model.h5')  # Replace 'trained_model.h5' with your trained model file\n",
    "\n",
    "# Load the distorted image\n",
    "distorted_image_path = 'distorted_outlined_B_2.png'  # Replace with the path to your distorted image\n",
    "distorted_image = load_img(distorted_image_path, target_size=image_size, color_mode='rgba')\n",
    "distorted_image_array = img_to_array(distorted_image)\n",
    "distorted_image_array = distorted_image_array.reshape(1, *distorted_image_array.shape)\n",
    "\n",
    "# Normalize the pixel values\n",
    "distorted_image_array = distorted_image_array / 255.0\n",
    "\n",
    "# Predict the label for the distorted image\n",
    "predicted_labels = model.predict(distorted_image_array)\n",
    "predicted_label_index = np.argmax(predicted_labels)\n",
    "predicted_label = characters[predicted_label_index]\n",
    "\n",
    "print('Predicted Label:', predicted_label)\n",
    "\n",
    "# Load the corresponding original image\n",
    "original_image_path = f'outlined_letter_{predicted_label}.png'  # Replace with the path to your original image directory\n",
    "original_image = load_img(original_image_path, target_size=image_size, color_mode='rgba')\n",
    "original_image_array = img_to_array(original_image)\n",
    "\n",
    "# Invert the colors of the original image\n",
    "inverted_image_array = 255 - original_image_array.astype(np.uint8)\n",
    "\n",
    "# Display the distorted and reconstructed images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(distorted_image)\n",
    "axes[0].set_title('Distorted Image')\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(inverted_image_array)\n",
    "axes[1].set_title('Reconstructed Image')\n",
    "axes[1].axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
