{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "456651f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbowe\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 27s 2s/step - loss: 133.6118 - accuracy: 0.0000e+00 - val_loss: 3.7440 - val_accuracy: 0.3696\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 23s 2s/step - loss: 3.6476 - accuracy: 0.1685 - val_loss: 3.5569 - val_accuracy: 0.6304\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 23s 2s/step - loss: 2.9409 - accuracy: 0.3820 - val_loss: 1.3566 - val_accuracy: 0.8261\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 23s 2s/step - loss: 1.2470 - accuracy: 0.6292 - val_loss: 0.4630 - val_accuracy: 0.9783\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.4721 - accuracy: 0.9101 - val_loss: 0.2202 - val_accuracy: 0.9348\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.2575 - accuracy: 0.9438 - val_loss: 0.0798 - val_accuracy: 0.9783\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1958 - accuracy: 0.9326 - val_loss: 0.1064 - val_accuracy: 0.9565\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1577 - accuracy: 0.9551 - val_loss: 0.0750 - val_accuracy: 0.9783\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0848 - accuracy: 0.9438 - val_loss: 0.0598 - val_accuracy: 0.9565\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0737 - accuracy: 0.9663 - val_loss: 0.0618 - val_accuracy: 0.9783\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0902 - accuracy: 0.9775 - val_loss: 0.0569 - val_accuracy: 0.9565\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0206 - accuracy: 0.9888 - val_loss: 0.1602 - val_accuracy: 0.9348\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0311 - accuracy: 0.9888 - val_loss: 0.2018 - val_accuracy: 0.9348\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0519 - accuracy: 0.9663 - val_loss: 0.0747 - val_accuracy: 0.9565\n",
      "Test loss: 0.07470237463712692\n",
      "Test accuracy: 0.95652174949646\n",
      "2/2 [==============================] - 1s 377ms/step\n",
      "Confusion Matrix:\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "characters = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!@#$%^&()')\n",
    "# Parameters\n",
    "image_size = (200, 200)\n",
    "input_shape = (*image_size, 4)  # 4 for RGBA\n",
    "n_classes = len(characters)\n",
    "batch_size = 8 \n",
    "epochs = 15\n",
    "\n",
    "# Load the image data\n",
    "image_files = []\n",
    "labels = []\n",
    "for char in characters:\n",
    "    for num in range(2, 5):\n",
    "        filename = f'distorted_outlined_{char}_{num}.png'\n",
    "        if os.path.exists(filename):\n",
    "            img = load_img(filename, target_size=image_size, color_mode='rgba')\n",
    "            img_array = img_to_array(img)\n",
    "            image_files.append(img_array)\n",
    "            labels.append(char)\n",
    "        else:\n",
    "            print(f\"File not found: {filename}\")\n",
    "encoder = OneHotEncoder(categories=[characters], handle_unknown='ignore')\n",
    "\n",
    "labels = np.array(labels).reshape(-1, 1)\n",
    "labels = encoder.fit_transform(labels).toarray()\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_files, labels, test_size=0.34, random_state=42, stratify=labels)\n",
    "\n",
    "\n",
    "\n",
    "# Build the model with increased complexity and regularization\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(n_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.fit(np.array(X_train), np.array(y_train), batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(np.array(X_test), np.array(y_test)),\n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(np.array(X_test), np.array(y_test), verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "model.save('trained_model.h5')\n",
    "\n",
    "y_pred = model.predict(np.array(X_test))\n",
    "predicted_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convert one-hot encoded labels back to original labels\n",
    "true_classes = np.argmax(np.array(y_test), axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confusion_mat = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Convert predicted_classes and true_classes back to one-hot-encoded form\n",
    "predicted_classes_onehot = keras.utils.to_categorical(predicted_classes, num_classes=n_classes)\n",
    "true_classes_onehot = keras.utils.to_categorical(true_classes, num_classes=n_classes)\n",
    "\n",
    "# Inverse transform the labels\n",
    "predicted_classes_labels = encoder.inverse_transform(predicted_classes_onehot)\n",
    "true_classes_labels = encoder.inverse_transform(true_classes_onehot)\n",
    "\n",
    "# Map from index to original labels\n",
    "index_to_label_map = {i: char for i, char in enumerate(characters)}\n",
    "\n",
    "predicted_classes_labels = [index_to_label_map[i] for i in predicted_classes]\n",
    "true_classes_labels = [index_to_label_map[i] for i in true_classes]\n",
    "\n",
    "# Compute the confusion matrix with original labels\n",
    "confusion_mat_labels = confusion_matrix(true_classes_labels, predicted_classes_labels)\n",
    "\n",
    "# Print the confusion matrix\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'confusion_mat' is the confusion matrix\n",
    "np.set_printoptions(threshold=np.inf)  # Set the threshold to infinity to print the entire matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "afc48c57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
      "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
      "       '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '!', '@', '#',\n",
      "       '$', '%', '^', '&', '(', ')'], dtype='<U1')]\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "{0: 1, 1: 1, 2: 6, 3: 1, 5: 2, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 17: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 2, 31: 1, 32: 1, 33: 1, 34: 1, 35: 1, 36: 1, 37: 2, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 1}\n",
      "{0: 2, 1: 2, 2: 2, 3: 2, 4: 2, 5: 2, 6: 1, 7: 2, 8: 2, 9: 2, 10: 2, 11: 2, 12: 2, 13: 2, 14: 2, 15: 2, 16: 1, 17: 2, 18: 2, 19: 2, 20: 2, 21: 2, 22: 2, 23: 2, 24: 2, 25: 2, 26: 2, 27: 2, 28: 2, 29: 2, 30: 1, 31: 2, 32: 2, 33: 2, 34: 2, 35: 2, 36: 2, 37: 1, 38: 2, 39: 2, 40: 2, 41: 2, 42: 2, 43: 2, 44: 2}\n",
      "{0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 2, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 2, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 2, 31: 1, 32: 1, 33: 1, 34: 1, 35: 1, 36: 1, 37: 2, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 1}\n",
      "{0: 1, 1: 1, 2: 6, 3: 1, 5: 2, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 17: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 2, 31: 1, 32: 1, 33: 1, 34: 1, 35: 1, 36: 1, 37: 2, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 1}\n",
      "Index 0 corresponds to label 'A'\n",
      "Index 1 corresponds to label 'B'\n",
      "Index 2 corresponds to label 'C'\n",
      "Index 3 corresponds to label 'D'\n",
      "Index 4 corresponds to label 'E'\n",
      "Index 5 corresponds to label 'F'\n",
      "Index 6 corresponds to label 'G'\n",
      "Index 7 corresponds to label 'H'\n",
      "Index 8 corresponds to label 'I'\n",
      "Index 9 corresponds to label 'J'\n",
      "Index 10 corresponds to label 'K'\n",
      "Index 11 corresponds to label 'L'\n",
      "Index 12 corresponds to label 'M'\n",
      "Index 13 corresponds to label 'N'\n",
      "Index 14 corresponds to label 'O'\n",
      "Index 15 corresponds to label 'P'\n",
      "Index 16 corresponds to label 'Q'\n",
      "Index 17 corresponds to label 'R'\n",
      "Index 18 corresponds to label 'S'\n",
      "Index 19 corresponds to label 'T'\n",
      "Index 20 corresponds to label 'U'\n",
      "Index 21 corresponds to label 'V'\n",
      "Index 22 corresponds to label 'W'\n",
      "Index 23 corresponds to label 'X'\n",
      "Index 24 corresponds to label 'Y'\n",
      "Index 25 corresponds to label 'Z'\n",
      "Index 26 corresponds to label '0'\n",
      "Index 27 corresponds to label '1'\n",
      "Index 28 corresponds to label '2'\n",
      "Index 29 corresponds to label '3'\n",
      "Index 30 corresponds to label '4'\n",
      "Index 31 corresponds to label '5'\n",
      "Index 32 corresponds to label '6'\n",
      "Index 33 corresponds to label '7'\n",
      "Index 34 corresponds to label '8'\n",
      "Index 35 corresponds to label '9'\n",
      "Index 36 corresponds to label '!'\n",
      "Index 37 corresponds to label '@'\n",
      "Index 38 corresponds to label '#'\n",
      "Index 39 corresponds to label '$'\n",
      "Index 40 corresponds to label '%'\n",
      "Index 41 corresponds to label '^'\n",
      "Index 42 corresponds to label '&'\n",
      "Index 43 corresponds to label '('\n",
      "Index 44 corresponds to label ')'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(encoder.categories_)\n",
    "#print(len(labels[:10]))\n",
    "print(labels[:10])\n",
    "print(np.unique(y_train, axis=0))\n",
    "print(np.unique(y_test, axis=0))\n",
    "\n",
    "\n",
    "#print(np.unique(predicted_classes, return_counts=True))\n",
    "\n",
    "unique, counts = np.unique(predicted_classes, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "unique, counts = np.unique(np.argmax(y_train, axis=1), return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(np.argmax(y_test, axis=1), return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "unique, counts = np.unique(predicted_classes, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "for index, label in enumerate(encoder.categories_[0]):\n",
    "    print(f\"Index {index} corresponds to label '{label}'\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2b020f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels before any transformation: 135\n",
      "Number of unique classes in y_train before one-hot encoding: 108\n",
      "Number of unique classes in y_test before one-hot encoding: 27\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique labels before any transformation: {len(labels)}\")\n",
    "\n",
    "\n",
    "print(f\"Number of unique classes in y_train before one-hot encoding: {len(y_train)}\")\n",
    "print(f\"Number of unique classes in y_test before one-hot encoding: {len(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "192dd193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 19s 19s/step\n",
      "Predicted Label: B\n",
      "Predicted Probabilities:\n",
      "A: 0.02213944122195244\n",
      "B: 0.02276305854320526\n",
      "C: 0.022226447239518166\n",
      "D: 0.022136615589261055\n",
      "E: 0.022534742951393127\n",
      "F: 0.022325176745653152\n",
      "G: 0.021595146507024765\n",
      "H: 0.021836817264556885\n",
      "I: 0.022440673783421516\n",
      "J: 0.022211942821741104\n",
      "K: 0.02219534106552601\n",
      "L: 0.022034157067537308\n",
      "M: 0.022215241566300392\n",
      "N: 0.02222779579460621\n",
      "O: 0.022144021466374397\n",
      "P: 0.022539600729942322\n",
      "Q: 0.021892927587032318\n",
      "R: 0.0222976952791214\n",
      "S: 0.022623850032687187\n",
      "T: 0.02247508428990841\n",
      "U: 0.022159723564982414\n",
      "V: 0.02199225313961506\n",
      "W: 0.021985545754432678\n",
      "X: 0.022235270589590073\n",
      "Y: 0.022165531292557716\n",
      "Z: 0.022304436191916466\n",
      "0: 0.02200223132967949\n",
      "1: 0.022135062143206596\n",
      "2: 0.022371923550963402\n",
      "3: 0.022258315235376358\n",
      "4: 0.022266104817390442\n",
      "5: 0.022075830027461052\n",
      "6: 0.022157523781061172\n",
      "7: 0.02231832593679428\n",
      "8: 0.022208642214536667\n",
      "9: 0.022612648084759712\n",
      "!: 0.022515026852488518\n",
      "@: 0.022045040503144264\n",
      "#: 0.022184723988175392\n",
      "$: 0.022463245317339897\n",
      "%: 0.021854637190699577\n",
      "^: 0.022295057773590088\n",
      "&: 0.022368863224983215\n",
      "(: 0.02190769463777542\n",
      "): 0.022260548546910286\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Parameters\n",
    "characters = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!@#$%^&()')\n",
    "image_size = (200, 200)\n",
    "input_shape = (*image_size, 4)  # 4 for RGBA\n",
    "n_classes = len(characters)\n",
    "\n",
    "# Load the trained model\n",
    "model = keras.models.load_model('trained_model.h5')  # Replace 'trained_model.h5' with your trained model file\n",
    "\n",
    "# Load the distorted image\n",
    "distorted_image_path = 'distorted_outlined_B_2.png'  # Replace with the path to your distorted image\n",
    "distorted_image = load_img(distorted_image_path, target_size=image_size, color_mode='rgba')\n",
    "distorted_image_array = img_to_array(distorted_image)\n",
    "distorted_image_array = distorted_image_array.reshape(1, *distorted_image_array.shape)\n",
    "\n",
    "# Normalize the pixel values\n",
    "distorted_image_array = distorted_image_array / 255.0\n",
    "\n",
    "# Predict the label for the distorted image\n",
    "predicted_labels = model.predict(distorted_image_array)\n",
    "predicted_label_index = np.argmax(predicted_labels)\n",
    "predicted_label = characters[predicted_label_index]\n",
    "\n",
    "\n",
    "print('Predicted Label:', predicted_label)\n",
    "print('Predicted Probabilities:')\n",
    "for i in range(n_classes):\n",
    "    print(f'{characters[i]}: {predicted_labels[0][i]}')\n",
    "    # Load the corresponding original image\n",
    "original_image_path = f'outlined_letter_{predicted_label}.png'  # Replace with the path to your original image directory\n",
    "original_image = load_img(original_image_path, target_size=image_size, color_mode='rgba')\n",
    "original_image_array = img_to_array(original_image)\n",
    "inverted_image_array = 255 - original_image_array.astype(np.uint8)    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(distorted_image)\n",
    "axes[0].set_title('Distorted Image')\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(inverted_image_array)\n",
    "axes[1].set_title('Reconstructed Image')\n",
    "axes[1].axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
